\begin{thebibliography}{xx}

\harvarditem[Ciresan et~al.]{Ciresan, Meier \harvardand\
  Schmidhuber}{2012}{image_classification_article}
Ciresan, D., Meier, U. \harvardand\ Schmidhuber, J.  \harvardyearleft
  2012\harvardyearright , `Multi-column deep neural networks for image
  classification'.
\newblock \\Accessed Jan 11 2022 [Online].

\harvarditem{Clark \harvardand\ Contributors}{2022}{pillow_about}
Clark, A. \harvardand\ Contributors  \harvardyearleft 2022\harvardyearright ,
  `From pillow documentation'.
\newblock \\Accessed Jan 8 2022 [Online].

\harvarditem{Fukushima}{1980}{neocognitron}
Fukushima, K.  \harvardyearleft 1980\harvardyearright , `Neocognitron: A
  self-organizing neural network model for a mechanism of pattern recognition
  unaffected by shift in position'.
\newblock \\Accessed Jan 11 2022 [Online].

\harvarditem[Harvey et~al.]{Harvey, Husbands \harvardand\
  Cliff}{1994}{inproceedings}
Harvey, I., Husbands, P. \harvardand\ Cliff, D.  \harvardyearleft
  1994\harvardyearright , Seeing the light: Artificial evolution, real vision,
  pp.~392--401.
\newblock \\Accessed Jan 7 2022 [Online].

\harvarditem{Kay}{2007}{tesseract_article}
Kay, A.  \harvardyearleft 2007\harvardyearright , `Tesseract: an open-source
  optical character recognition engine'.
\newblock \\Accessed Jan 8 2022 [Online].

\harvarditem{Knott}{2021}{eel_github}
Knott, C.  \harvardyearleft 2021\harvardyearright , `Eel github'.
\newblock \\Accessed Jan 10 2022 [Online].

\harvarditem{Nangia \harvardand\ Bowman}{2018}{ListOps}
Nangia, N. \harvardand\ Bowman, S.  \harvardyearleft 2018\harvardyearright ,
  `Listops: A diagnostic dataset for latent tree learning'.
\newblock \\Accessed Jan 7 2022 [Online].

\harvarditem{Peirson \harvardand\ Tolunay}{2018}{dank_learning}
Peirson, A.~L. \harvardand\ Tolunay, E.~M.  \harvardyearleft
  2018\harvardyearright , `Dank learning: Generating memes using deep neural
  networks'.
\newblock \\Accessed Jan 7 2022 [Online].

\harvarditem[Radford et~al.]{Radford, Wu, Child, Luan, Amodei \harvardand\
  Sutskever}{2019}{radford_wu_child_luan_amodei_sutskever_2019}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D. \harvardand\ Sutskever, I.
   \harvardyearleft 2019\harvardyearright , `Language models are unsupervised
  multitask learners'.
\newblock \\Accessed Jan 6 2022 [Online].

\harvarditem[Tay et~al.]{Tay, Denghani, Abnar, Shen, Bahri, Pham, Rao, Yang,
  Ruder \harvardand\ Metzler}{2020}{LRA_benchmark}
Tay, Y., Denghani, M., Abnar, S., Shen, Y., Bahri, D., Pham, P., Rao, J., Yang,
  L., Ruder, S. \harvardand\ Metzler, D.  \harvardyearleft
  2020\harvardyearright , `Long range arena: A benchmark for efficient
  transformers'.
\newblock \\Accessed Jan 7 2022 [Online].

\harvarditem[Valueva et~al.]{Valueva, Nagornov, Lyakhov, Valuev \harvardand\
  Chervyakov}{2020}{VALUEVA2020232}
Valueva, M., Nagornov, N., Lyakhov, P., Valuev, G. \harvardand\ Chervyakov, N.
  \harvardyearleft 2020\harvardyearright , `Application of the residue number
  system to reduce hardware costs of the convolutional neural network
  implementation', {\em Mathematics and Computers in Simulation} {\bf
  177},~232--243.
\newline\harvardurl{https://www.sciencedirect.com/science/article/pii/S0378475420301580}

\harvarditem[Vaswani et~al.]{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser \harvardand\ Polosukhin}{2017}{attention_is_all_you_need}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.,
  Kaiser, L. \harvardand\ Polosukhin, I.  \harvardyearleft
  2017\harvardyearright , `Attention is all you need'.
\newblock \\Accessed Jan 7 2022 [Online].

\end{thebibliography}
